# üß† Machine Learning Project - Housing Price Prediction

## üìå Overview
This project involves a **Machine Learning workflow** for **housing price prediction**, covering data preprocessing, exploratory data analysis (EDA), model training, evaluation, and conclusions.

The dataset used includes various housing features such as **location, number of rooms, population density, and median income**.

---

## üöÄ Project Workflow

### **1Ô∏è‚É£ Exploratory Data Analysis (EDA)**
- **Checked for missing values** and visualized them using a heatmap.
- **Descriptive statistics** were generated for better understanding of the dataset.
- **Visualizations** for insights:
  - Distribution of features
  - Correlations between variables
  - Identified important predictive features

### **2Ô∏è‚É£ Data Preprocessing**
- **Handled missing values** using `SimpleImputer(strategy='median')`.
- **Feature selection & transformation**:
  - Removed or encoded non-numeric categorical features (e.g., `ocean_proximity`).
  - Normalized numeric values for better model performance (optional).
- **Data Splitting**:
  - **Training:** 70%
  - **Validation:** 15%
  - **Testing:** 15%

### **3Ô∏è‚É£ Machine Learning Models**
- Implemented and compared:
  - **Linear Regression**
  - **Lasso Regression** (with `GridSearchCV` for hyperparameter tuning)

### **4Ô∏è‚É£ Model Evaluation**
- **Metric Used:**  
  - **Root Mean Squared Error (RMSE)** to measure predictive accuracy.
- **Results (example figures):**
  - Linear Regression RMSE: **~71,495**
  - Lasso Regression RMSE: **~71,944**
  - Final RMSE on Test Set: **~67,135**
- **Conclusions:**
  - **Slutsats:**
    - Den **linj√§ra regressionsmodellen** presterade bra, men **Lasso-regressionen** visade ett marginellt l√§gre RMSE p√• valideringsdata.
    - Skillnaden mellan modellerna √§r dock mycket liten, vilket tyder p√• att **feature selection** inte var avg√∂rande f√∂r detta PoC.
    - Det slutgiltiga testet bekr√§ftade modellens prestanda, men det finns fortfarande **utrymme f√∂r f√∂rb√§ttringar**.
    - N√§sta steg kan vara att testa mer avancerade modeller (s√•som **Random Forest** eller **XGBoost**) samt genomf√∂ra mer **feature engineering**.





